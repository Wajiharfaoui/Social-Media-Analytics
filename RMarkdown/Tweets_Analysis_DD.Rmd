---
title: "Predictions of online engagement for Dunkin Donuts tweets"
output: pdf_document
---
<style> body {text-align: justify} </style> <!-- Justify text. -->
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## The project's objective

The aim of this project is to help the social media manager of **Dunkin Donuts** to predict online engagement for his next.

## 

## The Project's steps

### Retrieving Data

The first thing we started with, is to get tweets posted by **Dunkin Donuts** official Twitter account while excluding **Retweets & Replies**.  
Using the Pagination, we ended up having a total of `793 tweets` with the following columns: `author_id`, `conversation_id`, `source`, `possibly_sensitive`, `id`, `text`, `reply_settings`, `lang`, `created_at`, `referenced_tweets`, `in_reply_to_user_id`, `public_metrics.retweet_count`, `public_metrics.reply_count`, `public_metrics.like_count`, `public_metrics.quote_count`,   
`entities.annotations`, `entities.urls`, `entities.mentions`, `entities.hashtags`, `attachments.media_keys`, `attachments.poll_ids`.     

### Feature Engineering

After binding all the tweets together in the same dataframe, we thought about creating new variables based on the one we got from Twitter. These tweets will bring more insights to our analysis and will help in creating our prediction model.  

The main features we came up with in this step are: 


-`Engagement variable` based on weighted average of likes, replies, quotes and retweets.  
-`Engagement categories` based on quantiles [1,4].  
-`Tweet Length` of original tweet with all hashtags and urls.  
-`Clean Tweet Length` after removing all hashtags and urls.  
-`Is_weekend` precising whether the tweet was posted during a weekday or not.  
-`Upper_count`giving the number of uppercase words per tweet.  
-`Exclamation_count`showing the frequency of exclamation marks inside the tweets.  
-`Hashtag_ct` counting the number of hashtags per tweet.  
-`Photos_count` precising the number of photos existing as an attachment by tweet.  
-`Videos_count`precising the number of videos existing as an attachment by tweet.  
-`Gifs_count`precising the number of gifs existing as an attachment by tweet.  
-`Other_media_count`precising the number of media types other than photos, videos and gifs, existing as an attachment by tweet.  
-`Emojis_count` giving the number of emojis per tweet.

### Sentiment Analysis 

In the meantime, we worked on assigning sentiment for our corpus.  
For this step, we tried different **dictionary-based approach** libraries, citing mainly:  
- `Sentimentr`: which is designed to quickly calculate text polarity sentiment in the English language at the sentence level, by attempting to take into account valence shifters (i.e., negators, amplifiers (intensifiers), de-amplifiers (downtoners), and adversative conjunctions) while maintaining speed.  
To analyze sentiment using this library we had to make some changes to our corpus by remove numbers, punctuation, URLs, hashtags, mentions, controls, special characters, leading and trailing white spaces and finally converting all the text to lowercase.  
- `Vader`: which is developed to deal with the language patterns used in social media such as: words that increase the sentiment like **great** or **love**, words that are all caps are often used to amplify emotion, marks such as **!** or **!!!** will increase the sentiment, social media slang words and emojis.  
As for this method, we did not need to bring any changes to the corpus so we applied the function directly to the raw tweets' text. 
After comparing these two methods' results, we chose to consider the **Vader** results since they were more accurate when doing random check on the data to see if the sentiment assigned goes with the content of the tweet or not.
 
### Topics' modeling 
As an additional feature we extracted the main topic for the tweets by implementing an LDA analysis. 
- As a first step we removed the emojis, normalized the text and removed irrelevant words (for the topic modeling). For this last step we identified the part of speech of each word in the tweet and after this we used the words classified as Adjectives, nouns, proper nouns and interjections. As a final step for cleaning we used the lemmatisation to extract the intended meaning of the words.  


- The second part of the analysis is related to finding the optimal number of topics for the LDA. For this process we calculated the metrics Griffiths2004, CaoJuan2009, Arun2010 and Deveaud2014. The graph corresponding to the metrics curves is shown below. 
```{r  echo=FALSE, fig.cap="metrics LDA", out.width = '100%'}
knitr::include_graphics("topics_num.png")
```

- According to the results the optimal number of topics is between 5 and 12, After iterating with different values we found a classification of 6 important topics which can be identified by the main words in the figure 2  


```{r  echo=FALSE, fig.cap="Topics description", out.width = '100%'}
knitr::include_graphics("topic_words.png")
```

- Finally, after analyzing the results we observed that the tweets with the lowest relationship with the topics were related to random topics or were very short to identify the real topic. For this reason we created a different topic to include the tweets with gammas less than 19%, this category is identified as "Others"   

### Model creation & evaluation 

```{r echo=FALSE}
```
The team proceeded with the model creation firstly by creating dummy variables of all categorical variables present in the selected features. Once these variables were added, the target variable was defined to be the **engagement_categ**, setting the purpose of the model to be a classification of the tweet between all pre-defined engagement categories, ranging from 1 to 4, where 1 is the less engaging and 4 the most engaging tweets categories.

The next step of this process was to split the data into training and testing set, choosing a stratified partition of 80% for the training and 20% for the test sets. Once we had the data ready to be processed, we compared different modelsâ€™ performance and chose the Multinomial Neural Network, provided by the **nnet** 	R package. The model predicted the tweets of the testing set in terms of probability for each category and we selected the highest probability as the chosen label. 

For the evaluation process we used the **ROCR** R package which allowed us to evaluate the AUC of the model, obtaining an AUC of approximately `71%`. The graph corresponding to the ROC curves of the model is shown below.

```{r pressure, echo=FALSE, fig.cap="ROC Curves", out.width = '40%'}
knitr::include_graphics("ROC_Curves.png")
```




\newpage

## Insights 

### Overview 

- Dunkin Donuts had the highest peak of tweets for the period of analysis, during  **September 2020**, with tweets about the **National Dunkin day** that took place on Tuesday, September 29, 2020, calling customers to visit DD's locals and announcing different offers on that occasion (`60 tweets`).  


```{r freq, echo=FALSE, out.width = '80%'}
knitr::include_graphics("freq.png")
```


- The majority of Dunkin Donuts tweets were publishing during the afternoon `64%`, followed by tweets posted during the evening `28%`, with a dominance for tweets published in the **weekdays** rather than **weekends**. 
```{r time, echo=FALSE, out.width = '80%'}
knitr::include_graphics("Time.png")
```

- **Diverse tweets** are the one dominating the coverage with `34%` of the share of voice, followed by tweets announcing **special offers** `14%`, and **special celebrations** posts `13%`.   
- Most of the tweets are with length around the **ideal tweet's length** which is **100 characters**, with the range [60-80] characters being the one with the highest number of tweets `114 tweets`.  

```{r length, echo=FALSE, out.width = '80%'}
knitr::include_graphics("length.png")
```

- Positive tweets are dominating the coverage with `59%` of overall tweets.  
- Positive tweets are keeping the lead of SOV overtime, with the highest peak being recorded during **April 2020**. This peak is fueled by posts praising the role played by the healthcare staff to save lives during the pandemic.  
```{r sentiment, echo=FALSE, fig.cap="ROC Curves", out.width = '80%'}
knitr::include_graphics("sentiment.png")
```

- `53%` of the total Dunkin Donuts tweets are tweets with **media attachements**, with **photos** being the most frequent media type to include with tweets `76%`.  

```{r media, echo=FALSE,  out.width = '80%'}
knitr::include_graphics("media.png")
```

\newpage

### Engagement

- In the graph shown below, it is perceivable that Dunkin Donuts' tweets vary within the engagement categories, therefore, their posts are not constant in terms of connecting to the people. As an example we can perceive that the peak for the **Not Engaging** category was during the month of **Dec 2020** whereas the peak for **Highly Engaging** tweets was during **September** of the same year.

```{r engag_categ, echo=FALSE, out.width = '80%'}
knitr::include_graphics("engag_categOT.PNG")
```

- As it is displayed in the **Engagement vs Day Over Time** graph, most of the tweets published by DD are done during weekdays, therefore, there is no proof that the day of the week affects the engagement of the tweet. Also, the month of **September** is the highest engaging month, due to the **#NationalDunkinDay**.

```{r engagmentOT, echo=FALSE, out.width = '80%'}
knitr::include_graphics("engagementOT.PNG")
```

\newpage

- The **Engagement vs. Topics** chart displays the distribuion of each topic vs engagement. Clearly, we can see that the most engaging topics are: **Special Celebrations **  and **Others**, followed by **Order by App/ Drive Thru**.

```{r engag_topic, echo=FALSE, out.width = '80%'}
knitr::include_graphics("topics_engagement.PNG")
```

- In the **Engagement vs Media** graph, we analyze the impact of media on tweet's engagement. Counterintuitively, highest engaging tweets do not contain media. However, most of the tweets belonging to the subsequent categories contain media.


```{r engag_media, echo=FALSE, out.width = '80%'}
knitr::include_graphics("engagementMedia.PNG")
```
